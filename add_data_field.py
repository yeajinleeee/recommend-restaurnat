from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import re
import csv
import math
import urllib.parse
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import concurrent.futures
import threading


SCROLL_PAUSE_TIME = 5
api_data_cnt = 0
api_data_lock = threading.Lock()

def get_driver():
    options = webdriver.ChromeOptions()
    options.add_argument('--no-sandbox')
    options.add_argument('disable-gpu')
    option.add_argument('headless')
    options.add_argument('--disable-dev-shm-usage')
    driver = webdriver.Chrome(options=options)
    return driver

def encode_url(url):
    return urllib.parse.quote(url, safe=":/?&=+")

def calculate_cosine_similarity(text1, text2):
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform([text1, text2])
    similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
    return similarity

def haversine(lat1, lon1, lat2, lon2):
    # ì§€êµ¬ì˜ ë°˜ì§€ë¦„ (ë‹¨ìœ„: km)
    R = 6371.0

    # ìœ„ë„ì™€ ê²½ë„ë¥¼ ë¼ë””ì•ˆìœ¼ë¡œ ë³€í™˜
    phi1 = math.radians(lat1)
    phi2 = math.radians(lat2)
    dphi = math.radians(lat2 - lat1)
    dlambda = math.radians(lon2 - lon1)

    # Haversine ê³µì‹ì„ ì´ìš©í•œ ê±°ë¦¬ ê³„ì‚°
    a = math.sin(dphi / 2)**2 + math.cos(phi1) * math.cos(phi2) * math.sin(dlambda / 2)**2
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))

    distance = R * c  # ê²°ê³¼ê°’ì€ í‚¬ë¡œë¯¸í„° ë‹¨ìœ„
    return distance


def search_google_map(driver, keyword, jibun, roadname, lat, lng):
    driver.get('https://www.google.com/maps/')
    wait = WebDriverWait(driver, 10)

    searchbox = driver.find_element(By.CSS_SELECTOR, 'input#searchboxinput')

    searchbox.send_keys(keyword)

    searchbutton = driver.find_element(By.CSS_SELECTOR, "button#searchbox-searchbutton")
    searchbutton.click()

    time.sleep(3)

    data = {k: "" for k in ["title", "address", "rating", "category", "review_cnt", "lat", "lng", "link"]}
    #print(f'ë„ë¡œëª… : {roadname} \n ì§€ë²ˆ : {jibun} ')
    print(f'{keyword}ì˜ ìœ„ê²½ë„  : {lat} , {lng}')

    current_url = driver.current_url
    get_data_idx = 1
    try:
        lat = float(lat)  # lat ê°’ì„ floatë¡œ ë³€í™˜
        lng = float(lng)  # lng ê°’ì„ floatë¡œ ë³€í™˜
    except ValueError:
        # ìœ„ë„ ë˜ëŠ” ê²½ë„ê°€ ìˆ«ìê°€ ì•„ë‹Œ ê²½ìš°, ë¹„ì–´ìˆëŠ” ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬
        #print("ìœ„ë„ì™€ ê²½ë„ê°€ ì˜ëª»ëœ ê°’ì…ë‹ˆë‹¤. ì£¼ì†Œìœ ì‚¬ë„(get_data í•¨ìˆ˜)ë¥¼ ì‚¬ìš©.")
        get_data_idx = 2
        return 0
    if "search" in current_url:
        scroll = driver.find_element(By.XPATH, '//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[1]/div[1]')
        childs = scroll.find_elements(By.CLASS_NAME, 'hfpxzc')
        childs_len = len(childs)

        print(f"ğŸ” ê²€ìƒ‰ëœ ë§›ì§‘ ê°œìˆ˜: {childs_len}ê°œ")

        for i in range(3, 3+2*childs_len, 2):
            time.sleep(1)
            global last_height
            global new_height
            
            last_height = driver.execute_script("return document.body.scrollHeight")
            number = 0
            while True:
                number = number+1
                scroll = driver.find_element(By.XPATH, '//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[1]/div[1]')
                driver.execute_script('arguments[0].scrollBy(0, 1000);', scroll)
                time.sleep(SCROLL_PAUSE_TIME)
                #print(f'last height: {last_height}')
                scroll = driver.find_element(By.XPATH, '//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[1]/div[1]')
                new_height = driver.execute_script("return arguments[0].scrollHeight", scroll)

                #print(f'new height: {new_height}')

                if number == i:
                    break

                if new_height == last_height:
                    break

                last_height = new_height
            try:
                wait.until(EC.element_to_be_clickable(
                    (By.XPATH, f'//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[1]/div[1]/div[{i}]/div/a')
                )).click()
            except Exception as e:
                return {"title": "", "address": "", "rating": "", "category": "", "review_cnt": "", "lat": "", "lng": "", "link":""}

            time.sleep(2)
            #data = get_data(data, roadname, jibun)
            if get_data_idx == 1:
                data = get_data_haversine(driver, data, lat, lng)
            else:
                data = get_data(driver, data, roadname, jibun)
                
            if not (data == 0):
                return data
            else:
                data = {k: "" for k in ["title", "address", "rating", "category", "review_cnt", "lat", "lng", "link"]}
    elif "place" in current_url:
        #data = get_data(data, roadname, jibun)
        if get_data_idx == 1:
            data = get_data_haversine(driver, data, lat, lng)
        else:
            data = get_data(driver, data, roadname, jibun)
        if (data == 0):
            data = {k: "" for k in ["title", "address", "rating", "category", "review_cnt", "lat", "lng", "link"]}

    return data

def get_data(driver, data, roadname, jibun):
    try:
        address = driver.find_element(By.XPATH, '//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[9]/div[3]/button/div/div[2]/div[1]').text
    except:
        try:
            address = driver.find_element(By.XPATH, '//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[7]/div[3]/button/div/div[2]/div[1]').text
        except:
            try:
                address = driver.find_element(By.XPATH, '//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[8]/div[3]/button/div/div[2]/div[1]').text
            except:
                driver.back()
                return 0
    #print(f'ê²€ìƒ‰ ì£¼ì†Œ : {address}')
    roadname_similarity = calculate_cosine_similarity(roadname ,address)
    jibun_similarity = calculate_cosine_similarity(jibun ,address)

    print(f"ì§€ë²ˆ ì£¼ì†Œ ìœ ì‚¬ë„ : {roadname_similarity}, ë„ë¡œëª… ì£¼ì†Œ ìœ ì‚¬ë„ : {jibun_similarity}\n")
    if not (roadname_similarity >= 0.7 or jibun_similarity >= 0.7):
        driver.back()
        return 0
    

    data["title"] = driver.find_element(By.XPATH,'//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div/div[1]/div[1]/h1').text
    data["address"] = address
    
        
    try:
        data["rating"] = driver.find_elementd_element(By.XPATH,'//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div/div[1]/div[2]/div/div[1]/div[2]/span[1]/span[1]').text
    except:
        data["rating"] = "none"
    try:
        data["category"] = driver.find_element(By.XPATH,'//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div/div[1]/div[2]/div/div[2]/span[1]/span/button').text
    except:
        data["category"] = "none"
    try:
        data["review_cnt"] = driver.find_element(By.XPATH,'//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div/div[1]/div[2]/div/div[1]/div[2]/span[2]/span/span').text
    except:
        data["review_cnt"] = "none"
    url = driver.current_url
    data["link"] = url
    match = re.search(r'!3d([0-9\.\-]+)!4d([0-9\.\-]+)', url)
    if match:
        data["lat"], data["lng"] = match.group(1), match.group(2)
    else:
        data["lat"], data["lng"] = "", ""

    return data

def get_data_haversine(driver, data, lat, lng):
    
    url = driver.current_url
    match = re.search(r'!3d([0-9\.\-]+)!4d([0-9\.\-]+)', url)
    if match:
        data["lat"], data["lng"] = float(match.group(1)), float(match.group(2))
    else:
        data["lat"], data["lng"] = "", ""
    #print(f'ê²€ìƒ‰ ìœ„ê²½ë„  : {data["lat"]}, {data["lng"]}')
    
    distance = haversine(lat, lng, data["lat"], data["lng"])
    if(haversine(lat, lng, data["lat"], data["lng"]) >= 0.025):
        driver.back()
        return 0
    else:
        print(f"{distance}ì°¨ì´ëŠ” ê°™ì€ ì¥ì†Œì…ë‹ˆë‹¤. csvì— ì¶”ê°€í•˜ì˜€ìŠµë‹ˆë‹¤.")
    try:
        address = driver.find_element(By.XPATH, '//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[9]/div[3]/button/div/div[2]/div[1]').text
    except:
        try:
            address = driver.find_element(By.XPATH, '//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[7]/div[3]/button/div/div[2]/div[1]').text
        except:
            try:
                address = driver.find_element(By.XPATH, '//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[8]/div[3]/button/div/div[2]/div[1]').text
            except:
                driver.back()
                return 0
    
    data["title"] = driver.find_element(By.XPATH,'//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div/div[1]/div[1]/h1').text
    data["address"] = address
    data["link"] = url    
    try:
        data["rating"] = driver.find_element(By.XPATH,'//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div/div[1]/div[2]/div/div[1]/div[2]/span[1]/span[1]').text
    except:
        data["rating"] = "none"
    try:
        data["category"] = driver.find_element(By.XPATH,'//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div/div[1]/div[2]/div/div[2]/span[1]/span/button').text
    except:
        data["category"] = "none"
    try:
        data["review_cnt"] = driver.find_element(By.XPATH,'//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div/div[1]/div[2]/div/div[1]/div[2]/span[2]/span/span').text
    except:
        data["review_cnt"] = "none"

    #print(f'link : {data["link"]}')
    return data

def process_row(row):
    global api_data_cnt
    
    keyword = row["ì‚¬ì—…ì¥ëª…"] + " " + row["êµ¬"]
    jibun = row["ì§€ë²ˆì£¼ì†Œ"]
    roadname = row["ë„ë¡œëª…ì£¼ì†Œ"]
    lat = row["ìœ„ë„"]
    lng = row["ê²½ë„"]

    driver = get_driver()

    try:
        extra_data = search_google_map(driver, keyword, jibun, roadname, lat, lng)
        if extra_data == 0:
            extra_data = {k: "" for k in ["title", "address", "rating", "category", "review_cnt", "lat", "lng", "link"]}
        else:
            with api_data_lock:
                api_data_cnt += 1
    except Exception as e:
        print(f"ì—ëŸ¬ ë°œìƒ: {e}")
        extra_data = {k: "" for k in ["title", "address", "rating", "category", "review_cnt", "lat", "lng", "link"]}
    
    driver.quit()

    row.update({
        "êµ¬ê¸€ê°€ê²Œëª…": extra_data["title"],
        "êµ¬ê¸€ì£¼ì†Œ": extra_data["address"],
        "ë³„ì ": extra_data["rating"],
        "ì¹´í…Œê³ ë¦¬": extra_data["category"],
        "ë¦¬ë·°ìˆ˜": extra_data["review_cnt"],
        "êµ¬ê¸€ìœ„ë„": extra_data["lat"],
        "êµ¬ê¸€ê²½ë„": extra_data["lng"],
        "ì§€ë„ë§í¬": encode_url(extra_data["link"])
    })
    return row
        
    

with open("part_2-1.csv", "r", encoding='utf-8-sig', errors='replace') as infile,\
open("ì„œìš¸ì‹œ ì¼ë°˜ìŒì‹ì (ì—°ë™)_part_2-1.csv", "w", encoding='utf-8-sig', newline="") as outfile:
    reader = csv.DictReader(infile)
    fieldnames = reader.fieldnames + ["êµ¬ê¸€ê°€ê²Œëª…", "êµ¬ê¸€ì£¼ì†Œ", "ë³„ì ", "ì¹´í…Œê³ ë¦¬", "ë¦¬ë·°ìˆ˜", "êµ¬ê¸€ìœ„ë„", "êµ¬ê¸€ê²½ë„", "ì§€ë„ë§í¬"]
    writer = csv.DictWriter(outfile, fieldnames=fieldnames, quoting=csv.QUOTE_MINIMAL)
    writer.writeheader()

    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        results = executor.map(process_row, reader)

        for row in results:
            writer.writerow(row)                         

print(f'api ì—°ë™ëœ ê°œìˆ˜ : {api_data_cnt}')

        
